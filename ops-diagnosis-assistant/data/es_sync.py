import os
import psycopg2
from elasticsearch import Elasticsearch
from dotenv import load_dotenv
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

load_dotenv()

class KnowledgeBaseSync:
    def __init__(self):
        # PostgreSQLè¿æ¥é…ç½®
        self.pg_config = {
            "host": os.getenv("POSTGRES_HOST", "localhost"),
            "port": os.getenv("POSTGRES_PORT", "5433"),
            "database": os.getenv("POSTGRES_DB", "ops_knowledge"),
            "user": os.getenv("POSTGRES_USER", "postgres"),
            "password": os.getenv("POSTGRES_PASSWORD", "123456")
        }
        
        # Elasticsearchè¿æ¥é…ç½®
        self.es_config = {
            "hosts": [f"http://{os.getenv('ELASTICSEARCH_HOST', 'localhost')}:{os.getenv('ELASTICSEARCH_PORT', '9200')}"],
            "verify_certs": False  # å¼€å‘ç¯å¢ƒå¯ä»¥å…³é—­è¯ä¹¦éªŒè¯
        }
        
        self.es_index = "fault_cases"
    
    def connect_postgres(self):
        """è¿æ¥PostgreSQL"""
        try:
            conn = psycopg2.connect(**self.pg_config)
            logger.info("âœ… PostgreSQLè¿æ¥æˆåŠŸ")
            return conn
        except Exception as e:
            logger.error(f"âŒ PostgreSQLè¿æ¥å¤±è´¥: {e}")
            return None
    
    def connect_elasticsearch(self):
        """è¿æ¥Elasticsearch"""
        try:
            es = Elasticsearch(**self.es_config)
            if es.ping():
                logger.info("âœ… Elasticsearchè¿æ¥æˆåŠŸ")
                return es
            else:
                logger.error("âŒ Elasticsearchè¿æ¥å¤±è´¥")
                return None
        except Exception as e:
            logger.error(f"âŒ Elasticsearchè¿æ¥å¤±è´¥: {e}")
            return None
    
    def create_es_index(self, es_client):
        """åˆ›å»ºElasticsearchç´¢å¼•"""
        index_mapping = {
            "mappings": {
                "properties": {
                    "id": {"type": "integer"},
                    "fault_type": {"type": "text", "analyzer": "standard"},
                    "symptoms": {"type": "text", "analyzer": "standard"},
                    "root_cause": {"type": "text", "analyzer": "standard"},
                    "solution": {"type": "text", "analyzer": "standard"},
                    "severity": {"type": "keyword"},
                    "frequency": {"type": "keyword"},
                    "combined_text": {"type": "text", "analyzer": "standard"}  # ç”¨äºå…¨æ–‡æœç´¢
                }
            },
            "settings": {
                "analysis": {
                    "analyzer": {
                        "default": {
                            "type": "standard"
                        }
                    }
                }
            }
        }
        
        try:
            # åˆ é™¤å·²å­˜åœ¨çš„ç´¢å¼•ï¼ˆå¼€å‘ç¯å¢ƒï¼‰
            if es_client.indices.exists(index=self.es_index):
                es_client.indices.delete(index=self.es_index)
                logger.info("ğŸ—‘ï¸ åˆ é™¤æ—§ç´¢å¼•")
            
            # åˆ›å»ºæ–°ç´¢å¼•
            es_client.indices.create(index=self.es_index, body=index_mapping)
            logger.info("âœ… Elasticsearchç´¢å¼•åˆ›å»ºæˆåŠŸ")
            return True
        except Exception as e:
            logger.error(f"âŒ ç´¢å¼•åˆ›å»ºå¤±è´¥: {e}")
            return False
    
    def sync_data_to_es(self):
        """åŒæ­¥æ•°æ®åˆ°Elasticsearch"""
        pg_conn = self.connect_postgres()
        es_client = self.connect_elasticsearch()
        
        if not pg_conn or not es_client:
            return False
        
        try:
            # åˆ›å»ºç´¢å¼•
            if not self.create_es_index(es_client):
                return False
            
            # ä»PostgreSQLè¯»å–æ•°æ®
            cursor = pg_conn.cursor()
            cursor.execute("""
                SELECT id, fault_type, symptoms, root_cause, solution, severity, frequency 
                FROM fault_cases
            """)
            
            records = cursor.fetchall()
            logger.info(f"ğŸ“Š ä»PostgreSQLè¯»å–åˆ° {len(records)} æ¡è®°å½•")
            
            # åŒæ­¥åˆ°Elasticsearch
            success_count = 0
            for record in records:
                doc = {
                    "id": record[0],
                    "fault_type": record[1],
                    "symptoms": record[2],
                    "root_cause": record[3],
                    "solution": record[4],
                    "severity": record[5],
                    "frequency": record[6],
                    "combined_text": f"{record[1]} {record[2]} {record[3]} {record[4]}"  # ç»„åˆæ–‡æœ¬ç”¨äºæœç´¢
                }
                
                # ç´¢å¼•æ–‡æ¡£
                es_client.index(index=self.es_index, id=record[0], body=doc)
                success_count += 1
            
            # åˆ·æ–°ç´¢å¼•ä½¿æ–‡æ¡£ç«‹å³å¯æœç´¢
            es_client.indices.refresh(index=self.es_index)
            
            logger.info(f"âœ… æˆåŠŸåŒæ­¥ {success_count}/{len(records)} æ¡è®°å½•åˆ°Elasticsearch")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åŒæ­¥å¤±è´¥: {e}")
            return False
        finally:
            pg_conn.close()
    
    def test_es_search(self):
        """æµ‹è¯•Elasticsearchæœç´¢åŠŸèƒ½"""
        es_client = self.connect_elasticsearch()
        if not es_client:
            return
        
        test_queries = [
            "CPUä½¿ç”¨ç‡é«˜",
            "å†…å­˜ä¸è¶³",
            "ç£ç›˜ç©ºé—´æ»¡",
            "ç½‘ç»œå»¶è¿Ÿ",
            "æ•°æ®åº“è¿æ¥"
        ]
        
        logger.info("ğŸ§ª æµ‹è¯•Elasticsearchæœç´¢åŠŸèƒ½...")
        
        for query in test_queries:
            search_body = {
                "query": {
                    "multi_match": {
                        "query": query,
                        "fields": ["symptoms", "fault_type", "root_cause", "combined_text"],
                        "fuzziness": "AUTO"
                    }
                },
                "size": 3
            }
            
            try:
                result = es_client.search(index=self.es_index, body=search_body)
                hits = result["hits"]["hits"]
                
                logger.info(f"ğŸ” æœç´¢ '{query}': æ‰¾åˆ° {len(hits)} æ¡ç›¸å…³è®°å½•")
                
                for hit in hits[:2]:  # åªæ˜¾ç¤ºå‰2æ¡
                    source = hit["_source"]
                    logger.info(f"   - {source['fault_type']} (ç›¸å…³åº¦: {hit['_score']:.2f})")
                    
            except Exception as e:
                logger.error(f"âŒ æœç´¢æµ‹è¯•å¤±è´¥ '{query}': {e}")

if __name__ == "__main__":
    sync_manager = KnowledgeBaseSync()
    
    print("ğŸ”„ å¼€å§‹åŒæ­¥æ•°æ®åˆ°Elasticsearch...")
    if sync_manager.sync_data_to_es():
        print("âœ… æ•°æ®åŒæ­¥å®Œæˆï¼")
        sync_manager.test_es_search()
    else:
        print("âŒ æ•°æ®åŒæ­¥å¤±è´¥")